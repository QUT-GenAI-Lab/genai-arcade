---
layout: tag
tag: limits
permalink: /tag/limits/
title: Limits
slug: limits
before: neutral-inputs
after: knowledge-cutoff
---

# Limits

Let’s think about limits, not just technical ones, but what it really means for a system to have boundaries.

Although generative AI feels seamless when we're running a prompt on our browser, it’s grounded in physical infrastructure. Somewhere, a a real computer is running the model. That means it consumes electricity, generates heat, and relies on materials mined from the Earth. These are planetary limits: environmental, economic, and resource-based.

But there are also technical limits. Running a large model costs money and energy. It requires powerful hardware and constant maintenance. These constraints shape how often, how widely, and how efficiently the model can be used. Sometimes, tools are added to stretch these limits. A model might quietly call in a search engine or a calculator to help out. But the model itself is still a snapshot in time, frozen at the moment it was trained.

## Then there are the limits built into the model itself:
- It has a *finite context window*: it can only consider a certain amount of text at once.
- It has a *knowledge cutoff*: it doesn’t know anything that happened after a specific date.
- It is *static*: once trained, it doesn’t learn or update on its own.
- It has *finite capacity*: it can’t store or recall everything, and it doesn’t have memory unless explicitly designed to.

These limits aren’t flaws, they’re part of the design. They remind us that even the most advanced AI is still a tool, shaped by physical, economic, and conceptual boundaries.

Understanding these limits helps us use AI more wisely, not as something magical or all-knowing, but as a system with edges, trade-offs, and responsibilities.
