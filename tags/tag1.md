---
layout: tag
tag: knowing
permalink: /tag/knowing/
title: Knowing
---

## Knowing

Let’s talk about what it means for a generative AI to “know” something.

Unlike a person, a language model doesn’t learn by observing the world or testing ideas. It doesn’t verify facts or form beliefs. Instead, it works through patterns, predicting the next word in a sequence based on what it has seen during training.

This kind of knowing is statistical. If certain words or phrases often appear together in its training data, the model learns to associate them. That’s why it sounds fluent and confident, even when it’s wrong. It doesn’t know in the way a scientist knows through experiment, or a historian through evidence, or a person through experience. It just estimates what’s likely to come next.

There are many ways of knowing:
- In science, knowledge is built through testing and replication.
- In law, knowledge is shaped by precedent and argument.
- In belief systems like religion, knowledge may be accepted through faith or tradition.

A language model doesn’t participate in any of these. It doesn’t reason, reflect, or understand. It generates.

That’s why it might say that 17 × 23 = 391, not because it calculated it, but because those numbers often appear together. It’s not doing math. It’s doing pattern recognition.

Understanding this helps us use AI more thoughtfully. It’s not a source of truth. It’s a refelction of how it has 'seen' the data that allows it to know. 
