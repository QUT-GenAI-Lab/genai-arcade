---
layout: tag
tag: knowing
permalink: /tag/knowing/
title: Knowing
---

## Knowing

This is all about how a generative AI “knows” things. It’s the model’s **epistemology**, its way of establishing what counts as a fact.

For a language model, knowing is mostly about **probability**. It doesn’t check facts against the world. It just predicts what word is likely to come next based on patterns it has seen in its training data. That’s why it can sound confident and still be wrong.

But there are many ways of knowing:

- In **science**, facts are established through evidence and repeatable experiments.
- In **religion**, belief can be accepted as fact without proof.
- In **law**, facts are decided through argument and precedent.

A language model doesn’t do any of that. It just guesses.

That’s also why it’s a terrible calculator. It doesn’t “know” that 17 times 23 is 391, it just knows that those numbers often appear together.
