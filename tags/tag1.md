---
layout: tag
tag: knowing
permalink: /tag/knowing/
title: Knowing
slug: knowing
before: explainer
after: probable-facts
---

# Knowing 

Let’s talk about what it means for a generative AI to “know” something.

Unlike a person, a language model doesn’t learn by observing the world or testing ideas. It doesn’t verify facts or form beliefs. Instead, it works through patterns, predicting the next word in a sequence based on what it has seen during training.

This kind of knowing is statistical. If certain words or phrases often appear together in its training data, the model learns to associate them. That’s why it sounds fluent and confident, even when it’s wrong. It doesn’t know in the way a scientist knows through experiment, or a historian through evidence, or a person through experience. It just estimates what’s likely to come next.

In this category of widgets, you get to explore how a LLM comes to *know* things - in philosophy we call this epistemology, the study of how we know what we know. 

Understanding the logics of how a LLM comes to know helps us use AI more thoughtfully. It’s not a source of truth. It’s a refelction of how it has 'seen' data that allows it to know. 
