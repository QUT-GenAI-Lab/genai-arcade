---
layout: tag
tag: training
permalink: /tag/training/
before: linkedin-generator
after: politeness
title: Training
slug: training
---

# Data

If *Knowing* is about how it knows, then *Data* is about what it can know. This is the model’s **ontology** — the shape and scope of its world.

A generative AI model doesn’t explore the world or gather new information. It only works with what it has been trained on. That training data comes from a vast collection of human-made content: books, websites, articles, forums, and social media. But this data isn’t neutral. It reflects the choices, values, and power structures of the people and systems that produced it.

Some languages are overrepresented. Some regions dominate the conversation. Some topics are filtered out, by design, by law, or by platform policy. Others are simply missing, because no one wrote them down, or because they were excluded from the digital record.

This means the model’s world is uneven. It knows a lot about some things, and very little about others. And that imbalance is political.

## Politics lives in data:
- Whose voices are included?
- Whose histories are told?
- What kinds of knowledge are considered valid?

For example, a model might know more about Western philosophy than Indigenous knowledge systems, not because one is more important, but because one is more present in the data. It might reflect dominant narratives about gender, race, or history, not because it believes them, but because they were repeated often in its sources.

Understanding this helps us see the model’s responses for what they are: not a mirror of the world, but a mirror of the data it was given — shaped by culture, power, and omission.
