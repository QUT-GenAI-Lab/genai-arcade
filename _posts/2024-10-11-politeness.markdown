---
layout: default
title:  "Politeness"
tags: data
before: linkedin-generator
after: milkless
---

## Politeness

When you talk to an AI, the way you phrase your prompt can change the kind of answer you get, even if you're asking the same thing.

That’s because large language models don’t understand meaning the way humans do.  
They generate text by recognising patterns in language. So if your prompt is very formal, the model will look for patterns that match formal writing like academic papers or official documents.  
If your prompt is super casual, it might pull from patterns found in message boards, social media, or everyday conversation.

And here’s the twist: those different styles of writing often come with different *facts*, *assumptions*, or *tones*.  
The same question might lead to very different answers depending on how you ask it.

In this widget, you can type a prompt and see how the model responds when your input is:
- **Formal**
- **Informal**
- **Exactly as you wrote it**

---

<iframe
	src="https://willsh1997-politeness-demo.hf.space"
	frameborder="0"
	width="850"
	height="450"
></iframe>

---

Compare the results. What changes? What stays the same?

## Reflections:

- Did the tone of the prompt change the kind of answer you got?
- Were the facts or examples different in the formal vs. informal versions?
- Which version felt more trustworthy and why?
- What does this tell you about how LLMs “understand” language?

---

## So What?

This experiment shows that LLMs don’t just respond to *what* you say they also respond to *how* you say it.

That makes them powerful tools for adapting tone and style.  
But it also means they can reflect biases or assumptions hidden in different types of language.

---

## What do you think?

- When might it be helpful to use a more formal prompt?
- When might informality be better?
- What does this mean for how we ask questions or how we judge the answers?


